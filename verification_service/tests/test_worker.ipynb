{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T04:41:59.196906Z",
     "start_time": "2024-06-25T04:41:55.540229Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import shutil\n",
    "import uuid\n",
    "from verification_service.worker.jobs import Supervisor, Worker\n",
    "from verification_service.storage.database import MongoDbConnector\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from functools import partial\n",
    "from verification_service import unique_id\n",
    "\n",
    "\n",
    "_outs = './test_outputs'\n",
    "if os.path.exists(_outs):\n",
    "    shutil.rmtree(_outs)\n",
    "\n",
    "\n",
    "def jobid(): return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "load_dotenv(\"../verification_service/.env\")\n",
    "uri = os.getenv(\"MONGO_DB_URI\")\n",
    "omex_source_dir = './examples/sbml-core'\n",
    "omex_name = 'Elowitz-Nature-2000-Repressilator.omex'\n",
    "omex_fp = os.path.join(omex_source_dir, omex_name)\n",
    "out_dir = './test_outputs'\n",
    "simulators = ['amici', 'copasi', 'tellurium']\n",
    "spec_name = 'cI mRNA'\n",
    "job_id = jobid()\n",
    "\n",
    "db_connector = MongoDbConnector(connection_uri=uri, database_id=\"service_requests\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoldyn is not properly installed in this environment and thus its process implementation cannot be registered. Please consult smoldyn documentation.\n",
      "Cannot register SimpleNeuron. Error:\n",
      "**\n",
      "No module named 'pyneuroml'\n",
      "**\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:41:59.402625Z",
     "start_time": "2024-06-25T04:41:59.201212Z"
    }
   },
   "cell_type": "code",
   "source": "supervisor = Supervisor(db_connector=db_connector)",
   "id": "fc2f44df59a7156e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:41:59.414375Z",
     "start_time": "2024-06-25T04:41:59.405331Z"
    }
   },
   "cell_type": "code",
   "source": "supervisor.jobs",
   "id": "d7cb48762b805377",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completed_jobs': [{'_id': ObjectId('667a45c9e50fa55eb77a45f7'),\n",
       "   'job_id': '053b2c1b-51a6-4a10-8252-594fce1efa8a',\n",
       "   'status': 'COMPLETED',\n",
       "   'timestamp': '2024-06-25 04:21:29.634498',\n",
       "   'comparison_id': 'test',\n",
       "   'results': None}],\n",
       " 'in_progress_jobs': [{'_id': ObjectId('667a45c9e50fa55eb77a45f6'),\n",
       "   'job_id': 'fa70243e-3602-4a23-84f9-ed44ea868f0b',\n",
       "   'status': 'IN_PROGRESS',\n",
       "   'timestamp': '2024-06-25 04:21:29.282452',\n",
       "   'comparison_id': 'test',\n",
       "   'worker_id': '72e9ffa0-e9bc-4d30-9e41-29a549ae36d2'}],\n",
       " 'pending_jobs': [{'_id': ObjectId('6679fb9ef0a7c3bb9d2ab155'),\n",
       "   'status': 'PENDING',\n",
       "   'job_id': '0fb705b6-4b63-4348-94aa-27d37ba9e60f',\n",
       "   'omex_path': '../tmp/Elowitz-Nature-2000-Repressilator.omex',\n",
       "   'simulators': ['amici', 'copasi', 'tellurium'],\n",
       "   'comparison_id': 'test',\n",
       "   'timestamp': '2024-06-24 23:05:02.045342',\n",
       "   'ground_truth_report_path': '../tmp/reports.h5',\n",
       "   'include_outputs': True}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:42:00.498930Z",
     "start_time": "2024-06-25T04:41:59.415715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# re-create loop here\n",
    "\n",
    "import asyncio\n",
    "from verification_service import load_arrows\n",
    "\n",
    "\n",
    "db_connector = MongoDbConnector(connection_uri=uri, database_id=\"service_requests\")\n",
    "supervisor = Supervisor(db_connector=db_connector)\n",
    "        \n",
    "\n",
    "async def fetch_jobs(supervisor: Supervisor, max_retries=5, delay=5):\n",
    "    pending_jobs = [job for job in supervisor.db_connector.db['pending_jobs'].find()]\n",
    "    async def _run_check():\n",
    "        if len(pending_jobs):\n",
    "            print('There are pending jobs')\n",
    "            result = await check_jobs(supervisor)\n",
    "            print('There are no pending jobs')\n",
    "            return result\n",
    "        else:\n",
    "            return None \n",
    "            \n",
    "    n_retries = 0\n",
    "    run = True\n",
    "    while run:\n",
    "        check = await _run_check()\n",
    "        if check is None:\n",
    "            n_retries += 1\n",
    "            await asyncio.sleep(delay)\n",
    "        if n_retries == max_retries:\n",
    "            run = False\n",
    "        else:\n",
    "            continue \n",
    "    return 0 \n",
    "        \n",
    "        \n",
    "async def check_jobs(supervisor, max_retries=5, delay=5) -> int:\n",
    "    job_queue = supervisor.pending_jobs\n",
    "    n_tries = 0\n",
    "    while True:\n",
    "        # count tries\n",
    "        n_tries += 1\n",
    "        if n_tries == max_retries + 1:\n",
    "            print(f'Max retries {max_retries} reached!')\n",
    "            break\n",
    "\n",
    "        if len(job_queue):\n",
    "            print('There are pending jobs.')\n",
    "            for i, job in enumerate(job_queue):\n",
    "                # get the next job in the queue based on the preferred_queue_index\n",
    "                job_doc = supervisor.pending_jobs.pop(supervisor.preferred_queue_index)\n",
    "                job_comparison_id = job_doc['comparison_id']\n",
    "                unique_id_query = {'comparison_id': job_comparison_id}\n",
    "                in_progress_job = supervisor.db_connector.db.in_progress_jobs.find_one(unique_id_query) or None\n",
    "                \n",
    "                _job_exists = partial(supervisor._job_exists, comparison_id=job_comparison_id)\n",
    "                if not _job_exists(collection_name='in_progress_jobs'):\n",
    "                    print(f\"In progress job does not yet exist for {job_comparison_id}\")\n",
    "                    in_progress_job_id = unique_id()\n",
    "                    worker_id = unique_id()\n",
    "                    id_kwargs = ['job_id', 'worker_id']\n",
    "                    in_prog_kwargs = dict(zip(\n",
    "                        id_kwargs,\n",
    "                        list(map(lambda k: unique_id(), id_kwargs))\n",
    "                    ))\n",
    "                    in_prog_kwargs['comparison_id'] = job_comparison_id\n",
    "                    \n",
    "                    supervisor.db_connector.insert_in_progress_job(**in_prog_kwargs)\n",
    "                    print(f\"Successfully created new progress job for {job_comparison_id}\")\n",
    "                    # await supervisor.async_refresh_jobs()\n",
    "                    \n",
    "                if not _job_exists(collection_name='completed_jobs'):\n",
    "                    print(f\"Completed job does not yet exist for {job_comparison_id}\")\n",
    "                    # pop in-progress job from internal queue and use it parameterize the worker\n",
    "                    in_prog_id = [job for job in db_connector.in_progress_jobs.find()].pop(supervisor.preferred_queue_index)['job_id']\n",
    "                    \n",
    "                    # double-check and verify doc\n",
    "                    in_progress_doc = supervisor.db_connector.db.in_progress_jobs.find_one({'job_id': in_prog_id})\n",
    "                    \n",
    "                    # generate new worker\n",
    "                    workers_id = in_progress_doc['worker_id']\n",
    "                    worker = supervisor.call_worker(job_params=job_doc, worker_id=workers_id)\n",
    "                    \n",
    "                    # add the worker to the list of workers (for threadsafety)\n",
    "                    supervisor.workers.insert(supervisor.preferred_queue_index, worker.worker_id)\n",
    "                    \n",
    "                    # the worker returns the job result to the supervisor who saves it as part of a new completed job in the database\n",
    "                    completed_doc = supervisor.db_connector.insert_completed_job(job_id=unique_id(), comparison_id=job_comparison_id, results=worker.job_result)\n",
    "                    \n",
    "                    # release the worker from being busy and refresh jobs\n",
    "                    supervisor.workers.pop(supervisor.preferred_queue_index)\n",
    "                    print(f\"Successfully created new completed job for {job_comparison_id}\")\n",
    "                    # await supervisor.async_refresh_jobs()\n",
    "            \n",
    "                # remove the job from queue\n",
    "                supervisor.pending_jobs.pop(i)\n",
    "        # sleep\n",
    "        print(f'Sleeping for {delay} seconds...')\n",
    "        await load_arrows(delay)\n",
    "                 \n",
    "    return 0"
   ],
   "id": "a131e38d9a2b3c77",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:21:29.790957Z",
     "start_time": "2024-06-25T04:21:29.152220Z"
    }
   },
   "cell_type": "code",
   "source": "result = await check_jobs(supervisor, max_retries=5, delay=3)",
   "id": "f0af2e2a5dc958c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are pending jobs.\n",
      "In progress job does not yet exist for test\n",
      "Successfully created new progress job for test\n",
      "Completed job does not yet exist for test\n",
      "Successfully created new completed job for test\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m check_jobs(supervisor, max_retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, delay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n",
      "Cell \u001B[0;32mIn[4], line 98\u001B[0m, in \u001B[0;36mcheck_jobs\u001B[0;34m(supervisor, max_retries, delay)\u001B[0m\n\u001B[1;32m     94\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully created new completed job for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjob_comparison_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     95\u001B[0m                 \u001B[38;5;66;03m# await supervisor.async_refresh_jobs()\u001B[39;00m\n\u001B[1;32m     96\u001B[0m         \n\u001B[1;32m     97\u001B[0m             \u001B[38;5;66;03m# remove the job from queue\u001B[39;00m\n\u001B[0;32m---> 98\u001B[0m             \u001B[43msupervisor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpending_jobs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;66;03m# sleep\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSleeping for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdelay\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: pop from empty list"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T04:45:41.904739Z",
     "start_time": "2024-06-25T04:45:41.901265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def f():\n",
    "    x = 0\n",
    "    while True:\n",
    "        print(f'x: {x}')\n",
    "        if x == 10:\n",
    "            print('done')\n",
    "            break\n",
    "\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "f()"
   ],
   "id": "2d02853504ce20a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0\n",
      "x: 1\n",
      "x: 2\n",
      "x: 3\n",
      "x: 4\n",
      "x: 5\n",
      "x: 6\n",
      "x: 7\n",
      "x: 8\n",
      "x: 9\n",
      "x: 10\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-25T04:42:43.901974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "async def f():\n",
    "    y = list(range(10))\n",
    "    z = []\n",
    "    n_tries = 0\n",
    "    max_try = 5\n",
    "    run = True \n",
    "    while run:\n",
    "        n_tries += 1\n",
    "        print(f'This is try number: {n_tries}')\n",
    "        if len(y):\n",
    "            v = y.pop(0)\n",
    "            z.append(v)\n",
    "        else:\n",
    "            if n_tries == max_try:\n",
    "                print('Max tries reached.')\n",
    "                run = False \n",
    "                print('exiting')\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "result = await f()\n",
    "\n",
    "result"
   ],
   "id": "99801f1edeee441d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supervisor.pending_jobs",
   "id": "61c8aa74aa7752c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supervisor.check_jobs()",
   "id": "f005de3bf6385eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. get an unassigned pending job by id\n",
    "job_id = supervisor.jobs['pending_jobs'].pop(0)"
   ],
   "id": "bc52d4fbe3785566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. fetch the respective document/job\n",
    "job_doc = supervisor.db_connector.db.pending_jobs.find_one({'job_id': job_id})"
   ],
   "id": "ee97da80e23bffcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "job_doc",
   "id": "8345463027d1c5ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "job_params = job_doc.copy()",
   "id": "cc5091bcd294c5bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os \n",
    "from verification_service import unique_id\n",
    "\n",
    "os.path.exists(job_params['omex_path'])"
   ],
   "id": "603082a45b57c709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3. Create a new in process job for the pending job we just picked up\n",
    "worker_id = unique_id()\n",
    "in_progress_job_id = unique_id()\n",
    "in_progress_doc = supervisor.db_connector.insert_in_progress_job(\n",
    "    job_id=in_progress_job_id,\n",
    "    worker_id=worker_id,\n",
    "    comparison_id=job_doc['comparison_id'],\n",
    ")\n",
    "\n",
    "in_progress_doc"
   ],
   "id": "e804aea0cffe0164",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4. Call the worker who will automatically process the job\n",
    "worker = Worker(job_params=job_params)"
   ],
   "id": "50521f80310bf489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4. Get the result from the worker and insert the new completed job for that comparison_id\n",
    "from verification_service import unique_id\n",
    "\n",
    "comparison_id = job_doc['comparison_id']\n",
    "\n",
    "completed_doc = supervisor.db_connector.insert_completed_job(\n",
    "    job_id=unique_id(),\n",
    "    comparison_id=comparison_id,\n",
    "    results=worker.job_result\n",
    ")"
   ],
   "id": "2a7a505a7a6ed538",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "completed_doc",
   "id": "2d457f7201db74f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test `Supervisor.initialize()`",
   "id": "fb9b7b99000cdd75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1df89daef32eb532",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "# case: uncompleted/pending jobs exist\n",
    "jobs_to_complete = pending\n",
    "if len(pending):\n",
    "    in_progress_jobs = supervisor.jobs['in_progress_jobs']\n",
    "    preferred_queue_index = supervisor.preferred_queue_index  # TODO: How can we make this more robust/dyn\n",
    "    "
   ],
   "id": "d394fb091f393652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supervisor.get_jobs()",
   "id": "96042befc59a466c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c85b3e7caa2ace2a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
