{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T05:21:54.382795Z",
     "start_time": "2024-06-25T05:21:50.918250Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import shutil\n",
    "import uuid\n",
    "from verification_service.worker.jobs import Supervisor, Worker\n",
    "from verification_service.storage.database import MongoDbConnector\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from functools import partial\n",
    "from verification_service import unique_id\n",
    "\n",
    "\n",
    "_outs = './test_outputs'\n",
    "if os.path.exists(_outs):\n",
    "    shutil.rmtree(_outs)\n",
    "\n",
    "\n",
    "def jobid(): return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "load_dotenv(\"../verification_service/.env\")\n",
    "uri = os.getenv(\"MONGO_DB_URI\")\n",
    "omex_source_dir = './examples/sbml-core'\n",
    "omex_name = 'Elowitz-Nature-2000-Repressilator.omex'\n",
    "omex_fp = os.path.join(omex_source_dir, omex_name)\n",
    "out_dir = './test_outputs'\n",
    "simulators = ['amici', 'copasi', 'tellurium']\n",
    "spec_name = 'cI mRNA'\n",
    "job_id = jobid()\n",
    "\n",
    "db_connector = MongoDbConnector(connection_uri=uri, database_id=\"service_requests\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoldyn is not properly installed in this environment and thus its process implementation cannot be registered. Please consult smoldyn documentation.\n",
      "Cannot register SimpleNeuron. Error:\n",
      "**\n",
      "No module named 'pyneuroml'\n",
      "**\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:21:54.594030Z",
     "start_time": "2024-06-25T05:21:54.383915Z"
    }
   },
   "cell_type": "code",
   "source": "supervisor = Supervisor(db_connector=db_connector)",
   "id": "fc2f44df59a7156e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:21:54.598Z",
     "start_time": "2024-06-25T05:21:54.594741Z"
    }
   },
   "cell_type": "code",
   "source": "supervisor.pending_jobs",
   "id": "d7cb48762b805377",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('6679fb9ef0a7c3bb9d2ab155'),\n",
       "  'status': 'PENDING',\n",
       "  'job_id': '0fb705b6-4b63-4348-94aa-27d37ba9e60f',\n",
       "  'omex_path': '../tmp/Elowitz-Nature-2000-Repressilator.omex',\n",
       "  'simulators': ['amici', 'copasi', 'tellurium'],\n",
       "  'comparison_id': 'test',\n",
       "  'timestamp': '2024-06-24 23:05:02.045342',\n",
       "  'ground_truth_report_path': '../tmp/reports.h5',\n",
       "  'include_outputs': True}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:21:55.478388Z",
     "start_time": "2024-06-25T05:21:54.599170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# re-create loop here\n",
    "\n",
    "import asyncio\n",
    "from verification_service import load_arrows\n",
    "\n",
    "\n",
    "db_connector = MongoDbConnector(connection_uri=uri, database_id=\"service_requests\")\n",
    "supervisor = Supervisor(db_connector=db_connector)\n",
    "        \n",
    "\n",
    "def _handle_in_progress_job(job_exists: bool, job_comparison_id: str):\n",
    "    if not job_exists:\n",
    "        print(f\"In progress job does not yet exist for {job_comparison_id}\")\n",
    "        in_progress_job_id = unique_id()\n",
    "        worker_id = unique_id()\n",
    "        id_kwargs = ['job_id', 'worker_id']\n",
    "        in_prog_kwargs = dict(zip(\n",
    "            id_kwargs,\n",
    "            list(map(lambda k: unique_id(), id_kwargs))\n",
    "        ))\n",
    "        in_prog_kwargs['comparison_id'] = job_comparison_id\n",
    "        \n",
    "        supervisor.db_connector.insert_in_progress_job(**in_prog_kwargs)\n",
    "        print(f\"Successfully created new progress job for {job_comparison_id}\")\n",
    "        # await supervisor.async_refresh_jobs()\n",
    "    else:\n",
    "        print(f'In Progress Job for {job_comparison_id} already exists. Now checking if it has been completed.')\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def _handle_completed_job(job_exists: bool, job_comparison_id: str, db_connector, supervisor, job_doc):\n",
    "    if not job_exists:\n",
    "        print(f\"Completed job does not yet exist for {job_comparison_id}\")\n",
    "        # pop in-progress job from internal queue and use it parameterize the worker\n",
    "        in_prog_id = [job for job in db_connector.in_progress_jobs.find()].pop(supervisor.preferred_queue_index)['job_id']\n",
    "        \n",
    "        # double-check and verify doc\n",
    "        in_progress_doc = supervisor.db_connector.db.in_progress_jobs.find_one({'job_id': in_prog_id})\n",
    "        \n",
    "        # generate new worker\n",
    "        workers_id = in_progress_doc['worker_id']\n",
    "        worker = supervisor.call_worker(job_params=job_doc, worker_id=workers_id)\n",
    "        \n",
    "        # add the worker to the list of workers (for threadsafety)\n",
    "        supervisor.workers.insert(supervisor.preferred_queue_index, worker.worker_id)\n",
    "        \n",
    "        # the worker returns the job result to the supervisor who saves it as part of a new completed job in the database\n",
    "        completed_doc = supervisor.db_connector.insert_completed_job(job_id=unique_id(), comparison_id=job_comparison_id, results=worker.job_result)\n",
    "        \n",
    "        # release the worker from being busy and refresh jobs\n",
    "        supervisor.workers.pop(supervisor.preferred_queue_index)\n",
    "        print(f\"Successfully created new completed job for {job_comparison_id}\")\n",
    "        # await supervisor.async_refresh_jobs()\n",
    "    else:\n",
    "        print(f'Completed Job for {job_comparison_id} already exists. Done with that job.')\n",
    "        \n",
    "    return True \n",
    "        \n",
    "async def check_jobs(supervisor, max_retries=5, delay=5) -> int:\n",
    "    job_queue = supervisor.pending_jobs\n",
    "    print(job_queue)\n",
    "    n_tries = 0\n",
    "    n_retries = 0\n",
    "    while True:\n",
    "        # count tries\n",
    "        n_tries += 1\n",
    "        if n_tries == max_retries + 1:\n",
    "            print(f'Max retries {max_retries} reached!')\n",
    "            break\n",
    "        \n",
    "        # if x is greater than 1 then it is a retry\n",
    "        if n_tries > 1:\n",
    "            print(f'{n_retries} is a retry. Running sim again.')\n",
    "            n_retries += 1\n",
    "\n",
    "        if len(job_queue) > 0:\n",
    "            print('There are pending jobs.')\n",
    "            for i, job in enumerate(job_queue):\n",
    "                # get the next job in the queue based on the preferred_queue_index\n",
    "                job_doc = job_queue.pop(supervisor.preferred_queue_index)\n",
    "                job_comparison_id = job_doc['comparison_id']\n",
    "                unique_id_query = {'comparison_id': job_comparison_id}\n",
    "                in_progress_job = supervisor.db_connector.db.in_progress_jobs.find_one(unique_id_query) or None\n",
    "                \n",
    "                _job_exists = partial(supervisor._job_exists, comparison_id=job_comparison_id)\n",
    "                \n",
    "                # check for in progress job with same comparison id and make a new one if not\n",
    "                in_progress_exists = _job_exists(collection_name='in_progress_jobs')\n",
    "                _handle_in_progress_job(in_progress_job, job_comparison_id)\n",
    "                \n",
    "                # do the same for completed jobs, which includes running the actual simulation comparison and returnin the results\n",
    "                completed_exists = _job_exists(collection_name='completed_jobs')\n",
    "                _handle_completed_job(completed_exists, job_comparison_id, supervisor.db_connector, supervisor, job_doc)\n",
    "            \n",
    "                # remove the job from queue\n",
    "                print(f'Job queue length: {len(job_queue)}')\n",
    "                if len(job_queue):\n",
    "                    job_queue.pop(0)\n",
    "        # sleep\n",
    "        print(f'Sleeping for {delay} seconds...')\n",
    "        await load_arrows(delay)\n",
    "        print()\n",
    "                 \n",
    "    return 0"
   ],
   "id": "a131e38d9a2b3c77",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:22:00.928314Z",
     "start_time": "2024-06-25T05:21:55.481265Z"
    }
   },
   "cell_type": "code",
   "source": "result = await check_jobs(supervisor, max_retries=5, delay=3)",
   "id": "f0af2e2a5dc958c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('6679fb9ef0a7c3bb9d2ab155'), 'status': 'PENDING', 'job_id': '0fb705b6-4b63-4348-94aa-27d37ba9e60f', 'omex_path': '../tmp/Elowitz-Nature-2000-Repressilator.omex', 'simulators': ['amici', 'copasi', 'tellurium'], 'comparison_id': 'test', 'timestamp': '2024-06-24 23:05:02.045342', 'ground_truth_report_path': '../tmp/reports.h5', 'include_outputs': True}]\n",
      "There are pending jobs.\n",
      "In Progress Job for test already exists.\n",
      "Completed job does not yet exist for test\n",
      "Successfully created new completed job for test\n",
      "Job queue length: 0\n",
      "Sleeping for 3 seconds...\n",
      "=>\n",
      "==>\n",
      "===>|\n",
      "0 is a retry. Running sim again.\n",
      "Sleeping for 3 seconds...\n",
      "=>\n",
      "==>\n",
      "===>|\n",
      "1 is a retry. Running sim again.\n",
      "Sleeping for 3 seconds...\n",
      "=>\n",
      "==>\n",
      "===>|\n",
      "2 is a retry. Running sim again.\n",
      "Sleeping for 3 seconds...\n",
      "=>\n",
      "==>\n",
      "===>|\n",
      "3 is a retry. Running sim again.\n",
      "Sleeping for 3 seconds...\n",
      "=>\n",
      "==>\n",
      "===>|\n",
      "Max retries 5 reached!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T05:03:10.762237Z",
     "start_time": "2024-06-25T05:03:07.410389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def f():\n",
    "    timer = 1\n",
    "    n_tries = 0\n",
    "    max_retries = 10\n",
    "    n_retries = 0\n",
    "    y = list(range(10))\n",
    "    x = 0\n",
    "    while True:\n",
    "        print(f'n retries: {n_retries}')\n",
    "        n_tries += 1\n",
    "        \n",
    "        # if x is greater than 1 then it is a retry\n",
    "        if n_tries > 1:\n",
    "            print(f'{x} is a retry. Running sim again.')\n",
    "            n_retries += 1\n",
    "         \n",
    "        # break if reached max tries\n",
    "        if n_retries == max_retries:\n",
    "            print('done')\n",
    "            break\n",
    "            \n",
    "        # exec 'simulation'\n",
    "        if len(y):\n",
    "            x += 1\n",
    "            z = y.pop(0)\n",
    "            print(f'Popped {z} out of y which has a len of {len(y)}')\n",
    "        \n",
    "        # regardless, sleep\n",
    "        print(f'sleeping at {x}')\n",
    "        await load_arrows(timer)\n",
    "    return x\n",
    "\n",
    "await f()"
   ],
   "id": "2d02853504ce20a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n retries: 0\n",
      "Popped 0 out of y which has a len of 9\n",
      "sleeping at 1\n",
      "=>|\n",
      "n retries: 0\n",
      "1 is a retry. Running sim again.\n",
      "Popped 1 out of y which has a len of 8\n",
      "sleeping at 2\n",
      "=>|\n",
      "n retries: 1\n",
      "2 is a retry. Running sim again.\n",
      "Popped 2 out of y which has a len of 7\n",
      "sleeping at 3\n",
      "=>|\n",
      "n retries: 2\n",
      "3 is a retry. Running sim again.\n",
      "Popped 3 out of y which has a len of 6\n",
      "sleeping at 4\n",
      "=>|\n",
      "n retries: 3\n",
      "4 is a retry. Running sim again.\n",
      "Popped 4 out of y which has a len of 5\n",
      "sleeping at 5\n",
      "=>|\n",
      "n retries: 4\n",
      "5 is a retry. Running sim again.\n",
      "Popped 5 out of y which has a len of 4\n",
      "sleeping at 6\n",
      "=>|\n",
      "n retries: 5\n",
      "6 is a retry. Running sim again.\n",
      "Popped 6 out of y which has a len of 3\n",
      "sleeping at 7\n",
      "=>|\n",
      "n retries: 6\n",
      "7 is a retry. Running sim again.\n",
      "Popped 7 out of y which has a len of 2\n",
      "sleeping at 8\n",
      "=>|\n",
      "n retries: 7\n",
      "8 is a retry. Running sim again.\n",
      "Popped 8 out of y which has a len of 1\n",
      "sleeping at 9\n",
      "=>|\n",
      "n retries: 8\n",
      "9 is a retry. Running sim again.\n",
      "Popped 9 out of y which has a len of 0\n",
      "sleeping at 10\n",
      "=>|\n",
      "n retries: 9\n",
      "10 is a retry. Running sim again.\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-25T04:42:43.901974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "async def f():\n",
    "    y = list(range(10))\n",
    "    z = []\n",
    "    n_tries = 0\n",
    "    max_try = 5\n",
    "    run = True \n",
    "    while run:\n",
    "        n_tries += 1\n",
    "        print(f'This is try number: {n_tries}')\n",
    "        if len(y):\n",
    "            v = y.pop(0)\n",
    "            z.append(v)\n",
    "        else:\n",
    "            if n_tries == max_try:\n",
    "                print('Max tries reached.')\n",
    "                run = False \n",
    "                print('exiting')\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "result = await f()\n",
    "\n",
    "result"
   ],
   "id": "99801f1edeee441d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supervisor.pending_jobs",
   "id": "61c8aa74aa7752c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supervisor.check_jobs()",
   "id": "f005de3bf6385eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. get an unassigned pending job by id\n",
    "job_id = supervisor.jobs['pending_jobs'].pop(0)"
   ],
   "id": "bc52d4fbe3785566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. fetch the respective document/job\n",
    "job_doc = supervisor.db_connector.db.pending_jobs.find_one({'job_id': job_id})"
   ],
   "id": "ee97da80e23bffcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "job_doc",
   "id": "8345463027d1c5ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "job_params = job_doc.copy()",
   "id": "cc5091bcd294c5bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os \n",
    "from verification_service import unique_id\n",
    "\n",
    "os.path.exists(job_params['omex_path'])"
   ],
   "id": "603082a45b57c709",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3. Create a new in process job for the pending job we just picked up\n",
    "worker_id = unique_id()\n",
    "in_progress_job_id = unique_id()\n",
    "in_progress_doc = supervisor.db_connector.insert_in_progress_job(\n",
    "    job_id=in_progress_job_id,\n",
    "    worker_id=worker_id,\n",
    "    comparison_id=job_doc['comparison_id'],\n",
    ")\n",
    "\n",
    "in_progress_doc"
   ],
   "id": "e804aea0cffe0164",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4. Call the worker who will automatically process the job\n",
    "worker = Worker(job_params=job_params)"
   ],
   "id": "50521f80310bf489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4. Get the result from the worker and insert the new completed job for that comparison_id\n",
    "from verification_service import unique_id\n",
    "\n",
    "comparison_id = job_doc['comparison_id']\n",
    "\n",
    "completed_doc = supervisor.db_connector.insert_completed_job(\n",
    "    job_id=unique_id(),\n",
    "    comparison_id=comparison_id,\n",
    "    results=worker.job_result\n",
    ")"
   ],
   "id": "2a7a505a7a6ed538",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "completed_doc",
   "id": "2d457f7201db74f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test `Supervisor.initialize()`",
   "id": "fb9b7b99000cdd75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1df89daef32eb532",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "# case: uncompleted/pending jobs exist\n",
    "jobs_to_complete = pending\n",
    "if len(pending):\n",
    "    in_progress_jobs = supervisor.jobs['in_progress_jobs']\n",
    "    preferred_queue_index = supervisor.preferred_queue_index  # TODO: How can we make this more robust/dyn\n",
    "    "
   ],
   "id": "d394fb091f393652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "supervisor.get_jobs()",
   "id": "96042befc59a466c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c85b3e7caa2ace2a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
